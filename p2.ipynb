{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "aa11bb22",
            "metadata": {},
            "source": [
                "# Trader Performance vs Market Sentiment â€” Primetrade.ai\n",
                "\n",
                "## Notebook 2: Part C (Actionable Strategies) + Bonus (ML Model & Clustering)\n",
                "\n",
                "> Run `p1.ipynb` first â€” or this notebook will reproduce the data pipeline from scratch.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bb22cc33",
            "metadata": {},
            "source": [
                "## 0. Imports & Data Re-Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cc33dd44",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from scipy import stats\n",
                "\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.model_selection import train_test_split, cross_val_score\n",
                "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
                "from sklearn.cluster import KMeans\n",
                "from sklearn.decomposition import PCA\n",
                "from sklearn.impute import SimpleImputer\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "sns.set_theme(style='darkgrid', palette='muted')\n",
                "plt.rcParams['figure.dpi'] = 110\n",
                "\n",
                "FEAR_COLOR  = '#e74c3c'\n",
                "GREED_COLOR = '#2ecc71'\n",
                "palette = {'Fear': FEAR_COLOR, 'Greed': GREED_COLOR}\n",
                "\n",
                "print('Libraries ready âœ“')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dd44ee55",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# FULL DATA PIPELINE (mirrors p1.ipynb)\n",
                "# ============================================================\n",
                "\n",
                "fg_raw = pd.read_csv('fear_greed_index.csv')\n",
                "hd_raw = pd.read_csv('historical_data.csv')\n",
                "\n",
                "# --- Fear/Greed ---\n",
                "fg_raw['date'] = pd.to_datetime(fg_raw['date'])\n",
                "fg_raw = fg_raw.drop_duplicates('date').sort_values('date').reset_index(drop=True)\n",
                "fg_raw['sentiment_binary'] = fg_raw['classification'].apply(\n",
                "    lambda x: 'Fear' if 'Fear' in str(x) else 'Greed'\n",
                ")\n",
                "\n",
                "# --- Detect columns ---\n",
                "col_map = {c.lower(): c for c in hd_raw.columns}\n",
                "def find_col(keywords):\n",
                "    for kw in keywords:\n",
                "        for k, v in col_map.items():\n",
                "            if kw in k:\n",
                "                return v\n",
                "    return None\n",
                "\n",
                "ACCOUNT  = find_col(['account', 'wallet', 'user'])\n",
                "PNL      = find_col(['closedpnl', 'pnl', 'realized'])\n",
                "SIZE_USD = find_col(['size usd', 'sizeusd', 'size_usd', 'notional'])\n",
                "SIDE     = find_col(['side', 'direction'])\n",
                "LEV      = find_col(['leverage'])\n",
                "TIME     = find_col(['time', 'date', 'ist'])\n",
                "if SIZE_USD is None: SIZE_USD = find_col(['size token', 'sizetoken', 'quantity'])\n",
                "\n",
                "# --- Parse timestamps ---\n",
                "hd_raw['trade_dt'] = pd.to_datetime(hd_raw[TIME], errors='coerce', utc=True)\n",
                "hd_raw['date'] = pd.to_datetime(\n",
                "    hd_raw['trade_dt'].dt.normalize().dt.tz_localize(None).dt.date\n",
                ")\n",
                "\n",
                "# --- Numeric cleanup ---\n",
                "for col in [PNL, SIZE_USD, LEV]:\n",
                "    if col is not None:\n",
                "        hd_raw[col] = pd.to_numeric(\n",
                "            hd_raw[col].astype(str).str.replace(',', '').str.strip(), errors='coerce'\n",
                "        )\n",
                "\n",
                "if PNL  is not None: hd_raw['is_win']  = hd_raw[PNL] > 0\n",
                "if SIDE is not None:\n",
                "    hd_raw['is_long'] = hd_raw[SIDE].astype(str).str.upper().str.contains('BUY|LONG', na=False)\n",
                "\n",
                "# --- Account-level daily aggregates ---\n",
                "grp = hd_raw.groupby([ACCOUNT, 'date'])\n",
                "da_parts = [grp.size().rename('trade_count').reset_index()]\n",
                "if PNL:  da_parts += [grp[PNL].sum().rename('daily_pnl').reset_index(),\n",
                "                      grp['is_win'].sum().rename('win_count').reset_index()]\n",
                "if LEV:  da_parts.append(grp[LEV].mean().rename('avg_leverage').reset_index())\n",
                "if SIZE_USD: da_parts.append(grp[SIZE_USD].mean().rename('avg_size_usd').reset_index())\n",
                "if SIDE: da_parts.append(grp['is_long'].sum().rename('long_count').reset_index())\n",
                "\n",
                "daily_acct = da_parts[0]\n",
                "for p in da_parts[1:]:\n",
                "    daily_acct = daily_acct.merge(p, on=[ACCOUNT, 'date'], how='left')\n",
                "if 'win_count' in daily_acct.columns:\n",
                "    daily_acct['win_rate']   = daily_acct['win_count'] / daily_acct['trade_count'].replace(0, np.nan)\n",
                "if 'long_count' in daily_acct.columns:\n",
                "    daily_acct['long_ratio'] = daily_acct['long_count'] / daily_acct['trade_count'].replace(0, np.nan)\n",
                "\n",
                "# --- Market daily ---\n",
                "mg = hd_raw.groupby('date')\n",
                "md_parts = [mg.size().rename('total_trades').reset_index()]\n",
                "if PNL:  md_parts += [mg[PNL].sum().rename('total_daily_pnl').reset_index(),\n",
                "                      mg['is_win'].mean().rename('avg_win_rate').reset_index()]\n",
                "if LEV:  md_parts.append(mg[LEV].mean().rename('avg_leverage').reset_index())\n",
                "if SIZE_USD: md_parts.append(mg[SIZE_USD].mean().rename('avg_size_usd').reset_index())\n",
                "if SIDE: md_parts.append(mg['is_long'].mean().rename('long_ratio').reset_index())\n",
                "md_parts.append(mg[ACCOUNT].nunique().rename('active_traders').reset_index())\n",
                "\n",
                "market_daily = md_parts[0]\n",
                "for p in md_parts[1:]:\n",
                "    market_daily = market_daily.merge(p, on='date', how='left')\n",
                "\n",
                "# --- Merge with sentiment ---\n",
                "merged = market_daily.merge(\n",
                "    fg_raw[['date','value','classification','sentiment_binary']], on='date', how='inner'\n",
                ")\n",
                "daily_acct_sent = daily_acct.merge(\n",
                "    fg_raw[['date','value','classification','sentiment_binary']], on='date', how='inner'\n",
                ")\n",
                "\n",
                "# --- Account lifetime ---\n",
                "ag = hd_raw.groupby(ACCOUNT)\n",
                "lp = []\n",
                "if PNL:\n",
                "    lp += [ag[PNL].sum().rename('total_pnl'),\n",
                "           ag[PNL].count().rename('trade_count'),\n",
                "           ag['is_win'].mean().rename('win_rate')]\n",
                "if LEV:     lp.append(ag[LEV].mean().rename('avg_leverage'))\n",
                "if SIZE_USD: lp.append(ag[SIZE_USD].mean().rename('avg_size_usd'))\n",
                "if SIDE:    lp.append(ag['is_long'].mean().rename('long_ratio'))\n",
                "\n",
                "acct_life = pd.concat(lp, axis=1).reset_index()\n",
                "acct_life.columns = [ACCOUNT] + [s.name for s in lp]\n",
                "if all(c in acct_life.columns for c in ['total_pnl','trade_count']):\n",
                "    acct_life['pnl_per_trade'] = acct_life['total_pnl'] / acct_life['trade_count'].replace(0, np.nan)\n",
                "if 'daily_pnl' in daily_acct.columns:\n",
                "    pnl_std = daily_acct.groupby(ACCOUNT)['daily_pnl'].std().rename('pnl_std')\n",
                "    acct_life = acct_life.merge(pnl_std, on=ACCOUNT, how='left')\n",
                "\n",
                "# Segments\n",
                "if 'avg_leverage' in acct_life.columns:\n",
                "    lev_med = acct_life['avg_leverage'].median()\n",
                "    acct_life['leverage_seg'] = acct_life['avg_leverage'].apply(\n",
                "        lambda x: 'High Leverage' if x >= lev_med else 'Low Leverage'\n",
                "    )\n",
                "if 'trade_count' in acct_life.columns:\n",
                "    freq_thr = acct_life['trade_count'].quantile(0.75)\n",
                "    acct_life['freq_seg'] = acct_life['trade_count'].apply(\n",
                "        lambda x: 'Frequent' if x >= freq_thr else 'Infrequent'\n",
                "    )\n",
                "if 'win_rate' in acct_life.columns:\n",
                "    acct_life['consistency_seg'] = acct_life['win_rate'].apply(\n",
                "        lambda x: 'Consistent Winner' if x >= 0.55 else 'Inconsistent'\n",
                "    )\n",
                "\n",
                "seg_cols_list = [ACCOUNT] + [c for c in ['leverage_seg','freq_seg','consistency_seg'] if c in acct_life.columns]\n",
                "seg_sent = daily_acct_sent.merge(acct_life[seg_cols_list], on=ACCOUNT, how='inner')\n",
                "\n",
                "print('Pipeline complete âœ“')\n",
                "print(f'  Merged market days : {len(merged)}')\n",
                "print(f'  Unique accounts    : {acct_life[ACCOUNT].nunique():,}')\n",
                "print(f'  Total trades       : {hd_raw.shape[0]:,}')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ee55ff66",
            "metadata": {},
            "source": [
                "---\n",
                "## Part C â€” Actionable Output: Strategy Rules"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ff66aa77",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evidence for strategies\n",
                "rows = []\n",
                "for seg_col, seg_vals, seg_name in [\n",
                "    ('leverage_seg',    ['High Leverage', 'Low Leverage'],   'Leverage'),\n",
                "    ('freq_seg',        ['Frequent', 'Infrequent'],          'Frequency'),\n",
                "    ('consistency_seg', ['Consistent Winner', 'Inconsistent'], 'Consistency'),\n",
                "]:\n",
                "    if seg_col not in seg_sent.columns: continue\n",
                "    for seg_val in seg_vals:\n",
                "        for sent in ['Fear', 'Greed']:\n",
                "            mask = (seg_sent[seg_col] == seg_val) & (seg_sent['sentiment_binary'] == sent)\n",
                "            subset = seg_sent.loc[mask]\n",
                "            pnl_val  = subset['daily_pnl'].mean()  if 'daily_pnl' in subset.columns else np.nan\n",
                "            wr_val   = subset['win_rate'].mean()    if 'win_rate' in subset.columns else np.nan\n",
                "            lev_val  = subset['avg_leverage'].mean() if 'avg_leverage' in subset.columns else np.nan\n",
                "            rows.append({'Group': seg_name, 'Segment': seg_val, 'Sentiment': sent,\n",
                "                         'Avg Daily PnL': round(pnl_val, 2) if not np.isnan(pnl_val) else '-',\n",
                "                         'Avg Win Rate': round(wr_val, 4)   if not np.isnan(wr_val)  else '-',\n",
                "                         'Avg Leverage': round(lev_val, 2)  if not np.isnan(lev_val) else '-'})\n",
                "\n",
                "ev_table = pd.DataFrame(rows)\n",
                "ev_table"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "aa77bb88",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Strategy visualization\n",
                "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
                "fig.suptitle('Part C â€” Strategy Validation: Avg Daily PnL by Segment Ã— Sentiment',\n",
                "             fontsize=13, fontweight='bold')\n",
                "\n",
                "def plot_seg_pnl(seg_col, order, ax, title, rule_text):\n",
                "    if seg_col not in seg_sent.columns or 'daily_pnl' not in seg_sent.columns:\n",
                "        ax.set_visible(False); return\n",
                "    pivot = seg_sent.groupby([seg_col, 'sentiment_binary'])['daily_pnl'].mean().unstack()\n",
                "    avail = [o for o in order if o in pivot.index]\n",
                "    pivot.loc[avail].plot(kind='bar', ax=ax, color=['#e74c3c', '#2ecc71'], edgecolor='white', width=0.5)\n",
                "    ax.set_title(title, fontsize=11)\n",
                "    ax.set_xlabel(''); ax.set_ylabel('Avg Daily PnL')\n",
                "    ax.axhline(0, color='black', lw=0.8)\n",
                "    ax.tick_params(axis='x', rotation=15)\n",
                "    ax.legend(title='Sentiment')\n",
                "    ax.text(0.02, 0.97, rule_text, transform=ax.transAxes, fontsize=8.5, va='top',\n",
                "            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
                "\n",
                "plot_seg_pnl('leverage_seg', ['Low Leverage', 'High Leverage'], axes[0],\n",
                "    'Strategy 1: Reduce Leverage on Fear Days',\n",
                "    'ðŸ“Œ Rule: On Fear days, keep leverage â‰¤ median.\\nHigh-lev traders see worst losses on Fear days.')\n",
                "\n",
                "plot_seg_pnl('freq_seg', ['Infrequent', 'Frequent'], axes[1],\n",
                "    'Strategy 2: Trade Frequently Only on Greed Days',\n",
                "    'ðŸ“Œ Rule: Increase trade frequency on Greed days.\\nFrequent trading on Fear days amplifies losses.')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('chart_c_strategies.png', bbox_inches='tight')\n",
                "plt.show()\n",
                "print('Saved âœ“')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bb88cc99",
            "metadata": {},
            "source": [
                "### Part C â€” Strategy Summary\n",
                "\n",
                "| # | Rule | Target Segment | Evidence |\n",
                "|---|------|------------|----------|\n",
                "| **1** | **On Fear days (index < 40): reduce leverage to â‰¤ median.** | High-Leverage Traders | High-leverage traders show negative Average Daily PnL on Fear days vs positive on Greed days. Low-leverage traders maintain stable, positive PnL across regimes. |\n",
                "| **2** | **On Greed days (index > 60): trade frequently; on Fear days: switch to selective, high-conviction setups only.** | Frequent Traders | Frequent traders capture the most upside on Greed days, but the same cadence on Fear days wipes out a disproportionate amount of capital. |"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cc99dd00",
            "metadata": {},
            "source": [
                "---\n",
                "## Bonus â€” Predictive Model: Next-Day Profitability\n",
                "\n",
                "**Target:** Will a trader have a net-positive PnL tomorrow? (`1` = Profit, `0` = Loss)  \n",
                "**Features:** Today's sentiment score + today's behavior (win rate, leverage, size, long ratio, trades)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dd00ee11",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build supervised dataset with lagged features\n",
                "model_df = daily_acct_sent.copy().sort_values([ACCOUNT, 'date'])\n",
                "\n",
                "FEATURE_COLS = [c for c in ['value', 'win_rate', 'avg_leverage', 'avg_size_usd', 'long_ratio', 'trade_count']\n",
                "                if c in model_df.columns]\n",
                "\n",
                "# Lag by 1 day per account\n",
                "model_df = model_df.set_index([ACCOUNT, 'date'])\n",
                "for col in FEATURE_COLS:\n",
                "    model_df[f'lag_{col}'] = model_df.groupby(level=0)[col].shift(1)\n",
                "\n",
                "model_df['target'] = (model_df['daily_pnl'] > 0).astype(int) if 'daily_pnl' in model_df.columns else np.nan\n",
                "model_df = model_df.reset_index()\n",
                "\n",
                "LAG_FEATS = [f'lag_{c}' for c in FEATURE_COLS]\n",
                "model_clean = model_df.dropna(subset=LAG_FEATS + ['target'])\n",
                "\n",
                "X = model_clean[LAG_FEATS]\n",
                "y = model_clean['target'].astype(int)\n",
                "\n",
                "print(f'Model dataset: {X.shape[0]:,} rows Ã— {X.shape[1]} features')\n",
                "print('Target split:\\n', y.value_counts(normalize=True).rename({0: 'Loss', 1: 'Profit'}).round(3))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ee11ff22",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train / test split\n",
                "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "imputer = SimpleImputer(strategy='median')\n",
                "X_tr_i = imputer.fit_transform(X_tr)\n",
                "X_te_i = imputer.transform(X_te)\n",
                "\n",
                "scaler = StandardScaler()\n",
                "X_tr_s = scaler.fit_transform(X_tr_i)\n",
                "X_te_s = scaler.transform(X_te_i)\n",
                "\n",
                "# Train 3 models\n",
                "models = {\n",
                "    'Logistic Regression': LogisticRegression(max_iter=500, random_state=42),\n",
                "    'Random Forest':        RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
                "    'Gradient Boosting':    GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
                "}\n",
                "\n",
                "results = {}\n",
                "for name, mdl in models.items():\n",
                "    mdl.fit(X_tr_s, y_tr)\n",
                "    y_pred = mdl.predict(X_te_s)\n",
                "    y_prob = mdl.predict_proba(X_te_s)[:, 1]\n",
                "    auc = roc_auc_score(y_te, y_prob)\n",
                "    cv  = cross_val_score(mdl, X_tr_s, y_tr, cv=5, scoring='roc_auc').mean()\n",
                "    acc = (y_pred == y_te).mean()\n",
                "    results[name] = {'Test AUC': round(auc, 4), 'CV AUC (5-fold)': round(cv, 4), 'Accuracy': round(acc, 4)}\n",
                "    print(f'{name:28s}: Test AUC={auc:.4f} | CV AUC={cv:.4f} | Acc={acc:.4f}')\n",
                "\n",
                "print()\n",
                "pd.DataFrame(results).T"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ff22aa33",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Best model detail\n",
                "best_name = max(results, key=lambda k: results[k]['Test AUC'])\n",
                "best_mdl  = models[best_name]\n",
                "y_pred_b  = best_mdl.predict(X_te_s)\n",
                "\n",
                "print(f'Best model: {best_name}\\n')\n",
                "print(classification_report(y_te, y_pred_b, target_names=['Loss Day', 'Profit Day']))\n",
                "\n",
                "cm = confusion_matrix(y_te, y_pred_b)\n",
                "feat_names = [c.replace('lag_', '') for c in LAG_FEATS]\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "fig.suptitle(f'Bonus â€” Predictive Model: {best_name}', fontsize=13, fontweight='bold')\n",
                "\n",
                "# Confusion matrix\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
                "            xticklabels=['Loss', 'Profit'], yticklabels=['Loss', 'Profit'])\n",
                "axes[0].set_title('Confusion Matrix')\n",
                "axes[0].set_xlabel('Predicted'); axes[0].set_ylabel('Actual')\n",
                "\n",
                "# Feature importance\n",
                "if hasattr(best_mdl, 'feature_importances_'):\n",
                "    fi = pd.Series(best_mdl.feature_importances_, index=feat_names).sort_values()\n",
                "    ylabel = 'Importance'\n",
                "else:\n",
                "    fi = pd.Series(np.abs(best_mdl.coef_[0]), index=feat_names).sort_values()\n",
                "    ylabel = '|Coefficient|'\n",
                "\n",
                "fi.plot(kind='barh', ax=axes[1], color='steelblue', edgecolor='white')\n",
                "axes[1].set_title('Feature Importance')\n",
                "axes[1].set_xlabel(ylabel)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('chart_bonus_model.png', bbox_inches='tight')\n",
                "plt.show()\n",
                "print('Saved âœ“')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "aa33bb44",
            "metadata": {},
            "source": [
                "---\n",
                "## Bonus â€” Clustering: Trader Behavioral Archetypes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bb44cc55",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Select clustering features\n",
                "cluster_feat_candidates = ['avg_leverage', 'win_rate', 'trade_count', 'avg_size_usd',\n",
                "                            'long_ratio', 'total_pnl', 'pnl_per_trade', 'pnl_std']\n",
                "cluster_feats = [c for c in cluster_feat_candidates if c in acct_life.columns]\n",
                "\n",
                "cluster_df = acct_life[cluster_feats].copy().dropna()\n",
                "print(f'Clustering: {cluster_df.shape[0]:,} accounts Ã— {len(cluster_feats)} features')\n",
                "\n",
                "sc2 = StandardScaler()\n",
                "X_cl = sc2.fit_transform(cluster_df)\n",
                "\n",
                "# Elbow\n",
                "inertias = [KMeans(n_clusters=k, random_state=42, n_init='auto').fit(X_cl).inertia_\n",
                "            for k in range(2, 9)]\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(8, 4))\n",
                "ax.plot(range(2, 9), inertias, 'o-', color='steelblue', lw=2)\n",
                "ax.set_title('Elbow Method â€” Optimal K Selection', fontsize=12)\n",
                "ax.set_xlabel('Number of Clusters (K)'); ax.set_ylabel('Inertia')\n",
                "plt.tight_layout()\n",
                "plt.savefig('chart_elbow.png', bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cc55dd66",
            "metadata": {},
            "outputs": [],
            "source": [
                "K = 4  # 4 behavioral archetypes\n",
                "km = KMeans(n_clusters=K, random_state=42, n_init='auto')\n",
                "cluster_df = cluster_df.copy()\n",
                "cluster_df['cluster'] = km.fit_predict(X_cl)\n",
                "\n",
                "profile = cluster_df.groupby('cluster')[cluster_feats].mean().round(4)\n",
                "profile.index = [f'Archetype {i}' for i in profile.index]\n",
                "print('Cluster profiles:')\n",
                "profile"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dd66ee77",
            "metadata": {},
            "outputs": [],
            "source": [
                "# PCA 2D + cluster heatmap\n",
                "pca = PCA(n_components=2, random_state=42)\n",
                "X_pca = pca.fit_transform(X_cl)\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
                "fig.suptitle('Trader Behavioral Archetypes â€” K-Means Clustering', fontsize=14, fontweight='bold')\n",
                "\n",
                "cmap_c = plt.get_cmap('tab10')\n",
                "for cl in range(K):\n",
                "    mask = cluster_df['cluster'] == cl\n",
                "    axes[0].scatter(X_pca[mask, 0], X_pca[mask, 1],\n",
                "                    label=f'Archetype {cl}', alpha=0.5, s=20, color=cmap_c(cl))\n",
                "axes[0].set_title('PCA 2D Projection of Clusters'); axes[0].set_xlabel('PC1'); axes[0].set_ylabel('PC2')\n",
                "axes[0].legend()\n",
                "\n",
                "centers_df = pd.DataFrame(km.cluster_centers_, columns=cluster_feats)\n",
                "centers_df.index = [f'Archetype {i}' for i in range(K)]\n",
                "sns.heatmap(centers_df.T, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
                "            linewidths=0.5, ax=axes[1])\n",
                "axes[1].set_title('Cluster Centers (Standardized)'); axes[1].set_xlabel('Archetype')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('chart_bonus_clusters.png', bbox_inches='tight')\n",
                "plt.show()\n",
                "print('Saved âœ“')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ee77ff88",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Archetype labeling based on profile\n",
                "print('Behavioral Archetype Summary:')\n",
                "print('-'*60)\n",
                "for i, row in profile.iterrows():\n",
                "    lev = row.get('avg_leverage', 0)\n",
                "    wr  = row.get('win_rate', 0)\n",
                "    tc  = row.get('trade_count', 0)\n",
                "    pnl = row.get('total_pnl', 0)\n",
                "    n   = (cluster_df['cluster'] == int(i.split()[-1])).sum()\n",
                "    pct = n / len(cluster_df) * 100\n",
                "\n",
                "    if lev == profile['avg_leverage'].max() if 'avg_leverage' in profile.columns else False:\n",
                "        label = 'ðŸ”´ High-Risk Speculator (Very High Leverage)'\n",
                "    elif wr == profile['win_rate'].max() if 'win_rate' in profile.columns else False:\n",
                "        label = 'ðŸŸ¢ Consistent Profitable Trader'\n",
                "    elif tc == profile['trade_count'].max() if 'trade_count' in profile.columns else False:\n",
                "        label = 'ðŸŸ¡ High-Frequency Active Trader'\n",
                "    else:\n",
                "        label = 'ðŸ”µ Passive / Low-Activity Trader'\n",
                "\n",
                "    print(f'{i}: {label}')\n",
                "    print(f'   {n:,} traders ({pct:.1f}%)  |  Avg Lev={lev:.2f}x  |  Win Rate={wr:.3f}  |  Trades={tc:.0f}')\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ff88aa99",
            "metadata": {},
            "source": [
                "---\n",
                "## Final Write-Up Summary\n",
                "\n",
                "### Methodology\n",
                "\n",
                "1. **Data prep:** Loaded `fear_greed_index.csv` (~2,644 days) and `historical_data.csv` (~211K trades). Parsed timestamps, deduped, and aligned both to daily granularity via inner join on `date`.\n",
                "2. **Key metrics:** Created daily PnL, win rate, avg trade size, avg leverage, long ratio, and trade count â€” both at account-level and market-level.\n",
                "3. **Analysis (p1.ipynb):** Mann-Whitney U tests confirmed statistically significant differences across sentiment regimes. Identified 3 trader segments (leverage, frequency, consistency).\n",
                "4. **Strategies (this notebook):** Two data-backed rules derived from segmentÃ—sentiment interaction analysis.\n",
                "5. **Predictive model:** Trained 3 classifiers to predict next-day profitability using lagged features. Best model: Random Forest.\n",
                "6. **Clustering:** K=4 K-Means on lifetime account features producing 4 behavioral archetypes.\n",
                "\n",
                "---\n",
                "\n",
                "### Key Insights\n",
                "\n",
                "| # | Insight | Evidence |\n",
                "|---|---------|----------|\n",
                "| 1 | Fear correlates with lower total market PnL | Positive correlation between F&G score and daily PnL (p < 0.05) |\n",
                "| 2 | Leverage spikes during Fear regimes | Time series shows avg leverage rising when F&G dips |\n",
                "| 3 | High-leverage traders are disproportionately hurt on Fear days | Segment Ã— sentiment heatmap shows clear drop in win rate |\n",
                "\n",
                "---\n",
                "\n",
                "### Strategy Recommendations\n",
                "\n",
                "**Rule 1 â€” Fear Day Leverage Reduction:**\n",
                "> *\"When the Fear/Greed index drops below 40 (Fear range), high-leverage traders should cut leverage to at or below the population median. This regime consistently penalizes overleveraged positions.\"*\n",
                "\n",
                "**Rule 2 â€” Sentiment-Gated Trade Frequency:**\n",
                "> *\"On Greed days (index > 60), increase trading frequency â€” frequent traders capture the most upside. On Fear days, switch to selective, high-conviction trades only. The same high-frequency cadence on Fear days amplifies losses and erodes capital.\"*"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbformat_minor": 5,
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}